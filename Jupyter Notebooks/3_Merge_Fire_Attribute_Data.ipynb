{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc523e0c",
   "metadata": {},
   "source": [
    "# Common_Anal_Merge\n",
    "\n",
    "This notebook merges the combined distance data from the individual “fires_distance_{batch_no}.csv files joined with selected fire attribute data from USGS_Wildland_Fire_Combined_Dataset.csv.  After dropping data related to (1) fires prior to 1963; (2) fires further than 1250 miles from Kearney, Nebraska, and (3) fires that had a “curvedRIng” geometry, there were a total of 100972 fires.  Results saved to the file “fire_dat_merged.csv.\" \n",
    "\n",
    "\n",
    "\n",
    "# License\n",
    "The code in this notebook was developed by Sue Boyd in response to Assignment 1 in DATA 512, a course in the UW MS Data Science degree program. The code in this notebook is provided under the MIT license located in the same repository as this notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25395e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "import time, json, folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from geopy.geocoders import Nominatim\n",
    "from pyproj import Transformer, Geod\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import geodesic\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba8a72",
   "metadata": {},
   "source": [
    "# Step 1 Load and Clean Attributes Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0d898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suetb\\AppData\\Local\\Temp\\ipykernel_8756\\1271887303.py:5: DtypeWarning: Columns (0,2,3,10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  attributes= pd.read_csv(f, usecols=columns_to_include)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OID_</th>\n",
       "      <th>Assigned_Fire_Type</th>\n",
       "      <th>Fire_Year</th>\n",
       "      <th>GIS_Acres</th>\n",
       "      <th>Listed_Fire_Names</th>\n",
       "      <th>Listed_Fire_Dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>1860</td>\n",
       "      <td>3940.207089</td>\n",
       "      <td>Big Quilcene River (1)</td>\n",
       "      <td>Listed Other Fire Date(s): 2006-11-02 - NIFC D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>1860</td>\n",
       "      <td>772.518249</td>\n",
       "      <td>Harrison Lake (1)</td>\n",
       "      <td>Listed Other Fire Date(s): 2006-11-02 - NIFC D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>1860</td>\n",
       "      <td>333.020409</td>\n",
       "      <td>Tunnel Creek (1)</td>\n",
       "      <td>Listed Other Fire Date(s): 2006-11-02 - NIFC D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>1870</td>\n",
       "      <td>22294.993577</td>\n",
       "      <td>1870 (2)</td>\n",
       "      <td>Listed Other Fire Date(s): 2017-01-30 - NIFC D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>1870</td>\n",
       "      <td>36.985574</td>\n",
       "      <td>No Fire Name Provided (2)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OID_ Assigned_Fire_Type Fire_Year     GIS_Acres          Listed_Fire_Names  \\\n",
       "0    1           Wildfire      1860   3940.207089     Big Quilcene River (1)   \n",
       "1    2           Wildfire      1860    772.518249          Harrison Lake (1)   \n",
       "2    3           Wildfire      1860    333.020409           Tunnel Creek (1)   \n",
       "3    4           Wildfire      1870  22294.993577                   1870 (2)   \n",
       "4    5           Wildfire      1870     36.985574  No Fire Name Provided (2)   \n",
       "\n",
       "                                   Listed_Fire_Dates  \n",
       "0  Listed Other Fire Date(s): 2006-11-02 - NIFC D...  \n",
       "1  Listed Other Fire Date(s): 2006-11-02 - NIFC D...  \n",
       "2  Listed Other Fire Date(s): 2006-11-02 - NIFC D...  \n",
       "3  Listed Other Fire Date(s): 2017-01-30 - NIFC D...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataframe of attributes \n",
    "\n",
    "f = \"Data/Wildfire_Attributes_Raw/USGS_Wildland_Fire_Combined_Dataset.csv\"\n",
    "columns_to_include = [\"OID_\", \"Listed_Fire_Names\", \"Assigned_Fire_Type\", \"Fire_Year\", \"Listed_Fire_Dates\", \"GIS_Acres\"]  # The \n",
    "attributes= pd.read_csv(f, usecols=columns_to_include)\n",
    "attributes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc1af23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444179, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the shape of the datast \n",
    "attributes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf6e25",
   "metadata": {},
   "source": [
    "A few quirky entries in the file create duplicate rows\n",
    "Clean that up by dropping duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159840d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135072, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = attributes.drop_duplicates()\n",
    "attributes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80f0c2",
   "metadata": {},
   "source": [
    "We still have a few funky entries related to footnotes in the original file \n",
    "For example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0033ef0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82427            82428\n",
       "98304     is a dup (1)\n",
       "98305            82429\n",
       "Name: OID_, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes[\"OID_\"][82427:82430] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac55a91",
   "metadata": {},
   "source": [
    "Check for \"OID_\" values that are 8 charachters or more and likely invalid. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d7cee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at row 82428 OID id:  is a dup (1)\n",
      "at row 103747 OID id:  AL3370708555920130221\n",
      "at row 103748 OID id:  AL3377808553420130128\n",
      "at row 103749 OID id:  AL3374308553420130218\n",
      "at row 103750 OID id:  AL3373008554720130218\n",
      "at row 103751 OID id:  Are dups (1)\n",
      "at row 104567 OID id:  small subsequent burned area. (1)\n",
      "at row 104575 OID id:  GA3374908328320150121\n",
      "at row 104576 OID id:  dups (1)\n",
      "at row 104792 OID id:  dup (1)\n",
      "at row 116877 OID id:  AR3574809291720130327); also adjacent to AR3570009286920130411. (1)\n",
      "\n",
      "Row indices to drop:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[82428,\n",
       " 103747,\n",
       " 103748,\n",
       " 103749,\n",
       " 103750,\n",
       " 103751,\n",
       " 104567,\n",
       " 104575,\n",
       " 104576,\n",
       " 104792,\n",
       " 116877]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for weird OID values \n",
    "to_drop = []\n",
    "OID_list = attributes[\"OID_\"].tolist()\n",
    "   \n",
    "\n",
    "for i in range (attributes.shape[0]):\n",
    "    OID = OID_list[i]\n",
    "    if len(str(OID)) > 7:\n",
    "        print(\"at row\", i, \"OID id:\", OID)\n",
    "        to_drop.append(i)\n",
    "        \n",
    "print(\"\")\n",
    "print (\"Row indices to drop:\")\n",
    "to_drop        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed08e8",
   "metadata": {},
   "source": [
    "Delete the rows with nonconforming indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a40578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135061, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " attributes = attributes.drop(attributes.index[to_drop], axis=0)\n",
    "attributes.shape    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe4746",
   "metadata": {},
   "source": [
    "Now, clean up some columns with mixed datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28e0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the attributes OID colum is a mix of string and int, cooerce to numeric\n",
    "attributes['OID_'] = pd.to_numeric(attributes['OID_'], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394ad7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Fire Year column is a mix of string and int, cooerce to numeric\n",
    "attributes['Fire_Year'] = pd.to_numeric(attributes['Fire_Year'], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155cae4",
   "metadata": {},
   "source": [
    "# Step 2 Load and Concat Fire Distance Files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be59376",
   "metadata": {},
   "source": [
    "Load in fire data.  The code is flexible incase future datasets increase in size, but my datapull only had batches 2-27. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a82fed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Distance to Kearny</th>\n",
       "      <th>Closest long</th>\n",
       "      <th>Closest lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13077</td>\n",
       "      <td>1235.364800</td>\n",
       "      <td>-120.925443</td>\n",
       "      <td>35.655980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13078</td>\n",
       "      <td>1118.345499</td>\n",
       "      <td>-120.153343</td>\n",
       "      <td>39.383876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13079</td>\n",
       "      <td>1146.742793</td>\n",
       "      <td>-120.644932</td>\n",
       "      <td>39.199013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13080</td>\n",
       "      <td>2918.436681</td>\n",
       "      <td>-161.011130</td>\n",
       "      <td>65.320212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13081</td>\n",
       "      <td>1133.013745</td>\n",
       "      <td>-118.220333</td>\n",
       "      <td>34.433047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  Distance to Kearny  Closest long  Closest lat\n",
       "0     13077         1235.364800   -120.925443    35.655980\n",
       "1     13078         1118.345499   -120.153343    39.383876\n",
       "2     13079         1146.742793   -120.644932    39.199013\n",
       "3     13080         2918.436681   -161.011130    65.320212\n",
       "4     13081         1133.013745   -118.220333    34.433047"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"Data/fires_distance_2.csv\"\n",
    "fire_dist = pd.read_csv(f)\n",
    "fire_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd1f861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error adding batch no 28\n",
      "Possible batch doesn't exist\n",
      "Error adding batch no 29\n",
      "Possible batch doesn't exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(119030, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_no in range (3, 30):\n",
    "    try:\n",
    "        f = f\"Data/fires_distance_{batch_no}.csv\"\n",
    "        new = pd.read_csv(f)\n",
    "        fire_dist = pd.concat([fire_dist, new], axis=0)\n",
    "    except: \n",
    "        print(\"Error adding batch no\", batch_no)\n",
    "        print(\"Possible batch doesn't exist\")\n",
    "        \n",
    "fire_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa737ae",
   "metadata": {},
   "source": [
    "Looks like we got everything in batches 2-27, as desired. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e547da6",
   "metadata": {},
   "source": [
    "# Step 3 merge the attributes dataset and the distances dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6050f5",
   "metadata": {},
   "source": [
    "To merge attributes and distance data, join on the \"OBJECTID\" feild from the distance data to the \"OID_\" field in the attributes data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f1fe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OID_</th>\n",
       "      <th>Assigned_Fire_Type</th>\n",
       "      <th>Fire_Year</th>\n",
       "      <th>GIS_Acres</th>\n",
       "      <th>Listed_Fire_Names</th>\n",
       "      <th>Listed_Fire_Dates</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Distance to Kearny</th>\n",
       "      <th>Closest long</th>\n",
       "      <th>Closest lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90000</th>\n",
       "      <td>90001</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>133.415596</td>\n",
       "      <td>Ponderosa (3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90001.0</td>\n",
       "      <td>793.245478</td>\n",
       "      <td>-111.109134</td>\n",
       "      <td>34.307069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90001</th>\n",
       "      <td>90002</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>126.151102</td>\n",
       "      <td>Cave Springs (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90002.0</td>\n",
       "      <td>823.985696</td>\n",
       "      <td>-84.575482</td>\n",
       "      <td>36.923435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90002</th>\n",
       "      <td>90003</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>116.749996</td>\n",
       "      <td>WILLIAMS BUTTE (2), Williams Butte (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90003.0</td>\n",
       "      <td>1168.859894</td>\n",
       "      <td>-120.739282</td>\n",
       "      <td>47.427621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90003</th>\n",
       "      <td>90004</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>191.376117</td>\n",
       "      <td>STANSBURY ISLAND (3), TAB (3), TABBY (3), Stan...</td>\n",
       "      <td>Listed Wildfire Containment Date(s): 2004-10-1...</td>\n",
       "      <td>90004.0</td>\n",
       "      <td>703.664808</td>\n",
       "      <td>-112.502450</td>\n",
       "      <td>40.778192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90004</th>\n",
       "      <td>90005</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>114.275132</td>\n",
       "      <td>Finally (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90005.0</td>\n",
       "      <td>841.779135</td>\n",
       "      <td>-84.326940</td>\n",
       "      <td>36.734490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90005</th>\n",
       "      <td>90006</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>112.485449</td>\n",
       "      <td>SOUTH 1 (2), South 1 (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90006.0</td>\n",
       "      <td>833.861342</td>\n",
       "      <td>-113.877611</td>\n",
       "      <td>37.108638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90006</th>\n",
       "      <td>90007</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>110.973069</td>\n",
       "      <td>Rail Hollow (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90007.0</td>\n",
       "      <td>1055.039007</td>\n",
       "      <td>-79.595843</td>\n",
       "      <td>38.152189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90007</th>\n",
       "      <td>90008</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>107.175071</td>\n",
       "      <td>Lime Kiln (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90008.0</td>\n",
       "      <td>1050.235309</td>\n",
       "      <td>-79.737280</td>\n",
       "      <td>38.014634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90008</th>\n",
       "      <td>90009</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>105.966790</td>\n",
       "      <td>Crooked Creek (2)</td>\n",
       "      <td>Listed Ignition Date(s): 2004-03-25 (2) | List...</td>\n",
       "      <td>90009.0</td>\n",
       "      <td>639.625029</td>\n",
       "      <td>-107.947011</td>\n",
       "      <td>47.423763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90009</th>\n",
       "      <td>90010</td>\n",
       "      <td>Likely Wildfire</td>\n",
       "      <td>2004</td>\n",
       "      <td>102.174906</td>\n",
       "      <td>Ingram Draft (1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90010.0</td>\n",
       "      <td>1061.071321</td>\n",
       "      <td>-79.517863</td>\n",
       "      <td>38.049173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OID_ Assigned_Fire_Type  Fire_Year   GIS_Acres  \\\n",
       "90000  90001    Likely Wildfire       2004  133.415596   \n",
       "90001  90002    Likely Wildfire       2004  126.151102   \n",
       "90002  90003    Likely Wildfire       2004  116.749996   \n",
       "90003  90004           Wildfire       2004  191.376117   \n",
       "90004  90005    Likely Wildfire       2004  114.275132   \n",
       "90005  90006    Likely Wildfire       2004  112.485449   \n",
       "90006  90007    Likely Wildfire       2004  110.973069   \n",
       "90007  90008    Likely Wildfire       2004  107.175071   \n",
       "90008  90009           Wildfire       2004  105.966790   \n",
       "90009  90010    Likely Wildfire       2004  102.174906   \n",
       "\n",
       "                                       Listed_Fire_Names  \\\n",
       "90000                                      Ponderosa (3)   \n",
       "90001                                   Cave Springs (1)   \n",
       "90002             WILLIAMS BUTTE (2), Williams Butte (1)   \n",
       "90003  STANSBURY ISLAND (3), TAB (3), TABBY (3), Stan...   \n",
       "90004                                        Finally (1)   \n",
       "90005                           SOUTH 1 (2), South 1 (1)   \n",
       "90006                                    Rail Hollow (1)   \n",
       "90007                                      Lime Kiln (1)   \n",
       "90008                                  Crooked Creek (2)   \n",
       "90009                                   Ingram Draft (1)   \n",
       "\n",
       "                                       Listed_Fire_Dates  OBJECTID  \\\n",
       "90000                                                NaN   90001.0   \n",
       "90001                                                NaN   90002.0   \n",
       "90002                                                NaN   90003.0   \n",
       "90003  Listed Wildfire Containment Date(s): 2004-10-1...   90004.0   \n",
       "90004                                                NaN   90005.0   \n",
       "90005                                                NaN   90006.0   \n",
       "90006                                                NaN   90007.0   \n",
       "90007                                                NaN   90008.0   \n",
       "90008  Listed Ignition Date(s): 2004-03-25 (2) | List...   90009.0   \n",
       "90009                                                NaN   90010.0   \n",
       "\n",
       "       Distance to Kearny  Closest long  Closest lat  \n",
       "90000          793.245478   -111.109134    34.307069  \n",
       "90001          823.985696    -84.575482    36.923435  \n",
       "90002         1168.859894   -120.739282    47.427621  \n",
       "90003          703.664808   -112.502450    40.778192  \n",
       "90004          841.779135    -84.326940    36.734490  \n",
       "90005          833.861342   -113.877611    37.108638  \n",
       "90006         1055.039007    -79.595843    38.152189  \n",
       "90007         1050.235309    -79.737280    38.014634  \n",
       "90008          639.625029   -107.947011    47.423763  \n",
       "90009         1061.071321    -79.517863    38.049173  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now merge the attributes dataset and the distances dataset\n",
    "\n",
    "col1 = \"OID_\"\n",
    "col2 = \"OBJECTID\"\n",
    "\n",
    "merged_df = attributes.merge(fire_dist, left_on=col1, right_on=col2, how='left')\n",
    "merged_df[90000:90010]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3427bde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16031\n"
     ]
    }
   ],
   "source": [
    "# Find instances where there was an attribute entry but no distance entry\n",
    "# print out the OID of these \n",
    "\n",
    "#merged_df = merged_df.iloc[90000:100000]\n",
    "\n",
    "missing_dist  = merged_df[merged_df[col2].isnull()][\"OID_\"]\n",
    "print(len(missing_dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d64ac0",
   "metadata": {},
   "source": [
    "About 16K values with no distances sounds right.  We dropped the first ~12K because no year, and several other small blocks later in the data pull. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6046306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135061, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4018e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119030 119031\n"
     ]
    }
   ],
   "source": [
    "# Find instances where there was a distance entry\n",
    "# but no attribute entry\n",
    "# print out the OBJECTID of these \n",
    "\n",
    "OBJECTID_all = fire_dist[\"OBJECTID\"].drop_duplicates().tolist()\n",
    "OBJECTID_merged = merged_df[\"OBJECTID\"].drop_duplicates().tolist()\n",
    "print(len(OBJECTID_all), len(OBJECTID_merged))\n",
    "\n",
    "#missing_dist = []\n",
    "#i = 0\n",
    "#for obj in OBJECTID_all:\n",
    "    #i+=1\n",
    "    #if (i%1000 == 0):\n",
    "        #print(\"weve checked\", i)\n",
    "    #if not obj in OBJECTID_merged:\n",
    "        #print(\"Missing:\", obj)\n",
    "        #missing_dist.append(obj)\n",
    "\n",
    "#missing_dist        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c9e59c",
   "metadata": {},
   "source": [
    "There are no fire distance datapoints that were not merged.  There is one extra value for OBJECTID in the merged dataset because some entries have \"NAN\", representing there was no fire dist to merge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9a46d4",
   "metadata": {},
   "source": [
    "# Step 4: Polish the Merged Dataset \n",
    "In the next code blocks, we drop data that doesn't have an object ID or distance value and fires before 1963.\n",
    "Finally, we reset the index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03f094a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119030, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any rows that don't have an object ID \n",
    "final = merged_df[~merged_df[\"OBJECTID\"].isna()]\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c43b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118995, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any remaining rows that don't have a distance (these will be from \"curvedRings\")\n",
    "final = final[~final[\"Distance to Kearny\"].isna()]\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80354a",
   "metadata": {},
   "source": [
    "Looks like we had ~35 drops due to \"curvedRings\".  Sounds about right. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d7bb5",
   "metadata": {},
   "source": [
    "Now drop fires that were too far away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82c4432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 118995 fires, there were 16725 out of the 1250 mile range\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(102270, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will drop any fires where distance > 1250\n",
    "too_far = final[\"Distance to Kearny\"] > 1250\n",
    "print(f\"Of the {len(too_far)} fires, there were {sum(too_far)} out of the 1250 mile range\")\n",
    "final = final[~too_far]\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88bdf25",
   "metadata": {},
   "source": [
    "Now drop fires that were earlier than 1963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f767b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 102270 fires left, there were 1298 earlier than 1963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100972, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now drop any years less than 1963\n",
    "too_early = final[\"Fire_Year\"] < 1963\n",
    "print(f\"Of the {len(too_early)} fires left, there were {sum(too_early)} earlier than 1963\")\n",
    "final = final[~too_early]\n",
    "final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4d6dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index \n",
    "final.set_index('OID_', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c77b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b80817c",
   "metadata": {},
   "source": [
    "# Step 4: Save Cleaned and Merged Data to File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01fb49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= \"Data/fire_dat_merged.csv\"\n",
    "final.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118176c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
